{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "miscon_df = pd.read_csv('misconception_mapping.csv')\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "test_df = test_df.sort_values(by='QuestionId')\n",
    "miscon_df['CorrectPred'] = 0\n",
    "miscon_df['AppearInTest'] = 0\n",
    "miscon_df['Predicted'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load predictions\n",
    "res_df2 = pd.read_parquet('df_submission2.parquet', engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process pred df\n",
    "#count_top_n for recall and precision\n",
    "def process_pred(pred_df, test_df, count_top_n):\n",
    "    pred_df[['QuestionId', 'Answer']] = pred_df['QuestionId_Answer'].str.split('_', expand=True)\n",
    "\n",
    "    target = []\n",
    "    pred = []\n",
    "    for _, row in pred_df.iterrows():\n",
    "        question_id = row['QuestionId']\n",
    "        answer = row['Answer']\n",
    "        if int(question_id) in test_df['QuestionId'].values:\n",
    "            misconception_column = f'Misconception{answer}Id'\n",
    "            r = test_df[test_df['QuestionId'] == int(question_id)]\n",
    "            targ = int(r[misconception_column].values[0])\n",
    "            target.append(targ)\n",
    "            pred.append(row['MisconceptionId'])\n",
    "    calc_recall_precision(target, pred, count_top_n)\n",
    "    mapk_score = mapk(target, pred)\n",
    "    print(f'mapk score: {mapk_score}')\n",
    "\n",
    "#calculate recall and precision\n",
    "def calc_recall_precision(target, pred, count_top_n):\n",
    "    #print(pred)\n",
    "    for i in range(len(target)):\n",
    "        #check top 5 of pred, if any one is correct, it's counted\n",
    "        pred25 = [int(num) for num in pred[i].split()]\n",
    "        for j in range(count_top_n):\n",
    "            if j == 0:\n",
    "                miscon_df.loc[target[i], 'AppearInTest'] += 1\n",
    "                miscon_df.loc[pred25[j], 'Predicted'] += 1\n",
    "            if target[i] == pred25[j]:\n",
    "                miscon_df.loc[target[i], 'CorrectPred'] += 1\n",
    "                break\n",
    "    total_recall = 0\n",
    "    recall_len = 0\n",
    "    total_precision = 0\n",
    "    precision_len = 0\n",
    "    for i, row in miscon_df.iterrows():\n",
    "        if row['AppearInTest'] != 0:\n",
    "            total_recall += row['CorrectPred'] / row['AppearInTest']\n",
    "            recall_len += 1\n",
    "        if row['Predicted'] != 0:\n",
    "            total_precision += row['CorrectPred'] / row['Predicted']\n",
    "            precision_len += 1\n",
    "    recall = total_recall / recall_len\n",
    "    precision = total_precision / precision_len\n",
    "    print(f'recall: {recall}')\n",
    "    print(f'precision: {precision}')\n",
    "\n",
    "def apk(actual, predicted, k=25):\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    actual = [actual]\n",
    "    #comment below line if predicted is already a list\n",
    "    predicted = list(map(int, predicted.split()))\n",
    "\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "#from baseline.py\n",
    "def mapk(actual, predicted, k=25):\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.options.display.max_rows = None\n",
    "#print(test_df['SubjectName'].value_counts())\n",
    "\n",
    "#88 questions in test_df\n",
    "algebra_topics = ['Place Value', 'Expanding Single Brackets', 'BIDMAS',  'Multiplying and Dividing with Decimals', 'Adding and Subtracting with Decimals', 'Adding and Subtracting Negative Numbers', 'Converting between Fractions and Percentages', 'Mental Multiplication and Division', 'Linear Sequences (nth term)', 'Substitution into Formula', 'Writing Expressions', 'Other Sequences', 'Ordering Negative Numbers', 'Equivalent Fractions', 'Adding and Subtracting Fractions', 'Multiples and Lowest Common Multiple', 'Rounding to Decimal Places', 'Factors and Highest Common Factor', 'Expanding Double Brackets', 'Simplifying Fractions', 'Writing Ratios', 'Written Division', 'Sequences-Others', 'Simplifying Algebraic Fractions', 'Fractions of an Amount', 'Simultaneous Equations', 'Ordering Fractions', 'Expanding Triple Brackets and more', 'Multiplying Terms', 'Indirect (Inverse) Proportion', 'Dividing Fractions', 'implifying Expressions by Collecting Like Terms', 'Converting Mixed Number and Improper Fractions', 'Operations with Surds', 'Written Multiplication', 'Multiplying Fractions', 'Algebraic Proof', 'Rounding to Significant Figures', 'Factorising into a Double Bracket', 'Factorising into a Single Bracket']\n",
    "\n",
    "#28 questions in test_df\n",
    "linear_algebra_topics = ['Distance Between Two Co-ordinates', 'Graphical Solution of Simultaneous Equations', 'Plotting Lines from Tables of Values', 'Solving Linear Inequalities', 'Plotting Quadratics from Tables of Values', 'Quadratic Equations', 'Linear Equations', 'Function Machines', 'Reflection', 'Quadratic Graphs-Others', 'Translation and Vectors', 'Midpoint Between Two Co-ordinates', 'Finding the Gradient and Intercept of a Line from the Equation']\n",
    "\n",
    "#38 questions in test_df\n",
    "geometry_topics = ['Basic Angle Facts (straight line, opposite, around a point, etc)', 'Real Life Graphs', 'Volume and Capacity Units', 'Area of Simple Shapes', 'Squares, Cubes, etc', 'Names and Properties of 3D Shapes', 'Nets', 'Length Scale Factors in Similar Shapes', 'Measuring Angles', 'Missing Lengths', 'Construct Triangle', 'Properties of Polygons', 'Parts of a Circle', 'Volume of Non-Prisms', 'Co-ordinate Geometry with Straight Lines', 'Parallel Lines', 'Perimeter', 'Properties of Triangles', 'Right-angled Triangles (SOHCAHTOA)', 'Properties of Quadrilaterals']\n",
    "\n",
    "#11 questions in test_df\n",
    "other_topics = ['Estimation', 'Time', 'Types, Naming and Estimating', 'Trial and Improvement and Iterative Methods', 'Speed, Distance, Time', 'Systematic Listing Strategies']\n",
    "\n",
    "#13 questions in test_df\n",
    "stats_topics = ['Pie Chart', 'Averages (mean, median, mode) from a List of Data', 'Probability of Single Events', 'Pictogram', 'Time Series and Line Graphs', 'Venn Diagrams', 'Range and Interquartile Range from a List of Data', 'Averages and Range from Grouped Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "algebra_df = test_df[test_df['SubjectName'].isin(algebra_topics)]\n",
    "#print(len(algebra_df))\n",
    "la_df = test_df[test_df['SubjectName'].isin(linear_algebra_topics)]\n",
    "#print(len(la_df))\n",
    "geo_df = test_df[test_df['SubjectName'].isin(geometry_topics)]\n",
    "#print(len(geo_df))\n",
    "ot_df = test_df[test_df['SubjectName'].isin(other_topics)]\n",
    "#print(len(ot_df))\n",
    "stats_df = test_df[test_df['SubjectName'].isin(stats_topics)]\n",
    "#print(len(stats_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algebra\n",
      "recall: 0.22984749455337689\n",
      "precision: 0.12990196078431374\n",
      "mapk score: 0.1171275997319352\n",
      "\n",
      "linear algebra\n",
      "recall: 0.22717013888888893\n",
      "precision: 0.1257396449704142\n",
      "mapk score: 0.1316443826948029\n",
      "\n",
      "geometry\n",
      "recall: 0.2657475490196079\n",
      "precision: 0.135844250363901\n",
      "mapk score: 0.24562834929196628\n",
      "\n",
      "others\n",
      "recall: 0.27702546296296293\n",
      "precision: 0.14256569847856151\n",
      "mapk score: 0.29523809523809524\n",
      "\n",
      "stats\n",
      "recall: 0.28254219409282694\n",
      "precision: 0.14775031685678075\n",
      "mapk score: 0.22286295427599773\n"
     ]
    }
   ],
   "source": [
    "print('algebra')\n",
    "process_pred(res_df2, algebra_df, 5)\n",
    "print('\\nlinear algebra')\n",
    "process_pred(res_df2, la_df, 5)\n",
    "print('\\ngeometry')\n",
    "process_pred(res_df2, geo_df, 5)\n",
    "print('\\nothers')\n",
    "process_pred(res_df2, ot_df, 5)\n",
    "print('\\nstats')\n",
    "process_pred(res_df2, stats_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.28323108384458073\n",
      "precision: 0.13833932853717024\n",
      "mapk score: 0.16373559280668956\n"
     ]
    }
   ],
   "source": [
    "#all qns\n",
    "process_pred(res_df2, test_df, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
