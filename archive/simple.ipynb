{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    ")\n",
    "from transformers.tokenization_utils_fast import PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def clear():\n",
    "    for _ in range(5):\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "\n",
    "def apk(actual, predicted, k=25):\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "    score, hits = 0.0, 0.0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            hits += 1.0\n",
    "            score += hits / (i + 1.0)\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "\n",
    "def mapk(actual, predicted, k=25):\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train_df = pd.read_csv(\n",
    "    \"data/train.csv\",\n",
    "    dtype={\n",
    "        \"MisconceptionAId\": \"Int64\",\n",
    "        \"MisconceptionBId\": \"Int64\",\n",
    "        \"MisconceptionCId\": \"Int64\",\n",
    "        \"MisconceptionDId\": \"Int64\",\n",
    "    },\n",
    ").fillna(-1)\n",
    "df_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1869"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>ConstructId</th>\n",
       "      <th>ConstructName</th>\n",
       "      <th>SubjectId</th>\n",
       "      <th>SubjectName</th>\n",
       "      <th>CorrectAnswer</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>AnswerAText</th>\n",
       "      <th>AnswerBText</th>\n",
       "      <th>AnswerCText</th>\n",
       "      <th>AnswerDText</th>\n",
       "      <th>MisconceptionAId</th>\n",
       "      <th>MisconceptionBId</th>\n",
       "      <th>MisconceptionCId</th>\n",
       "      <th>MisconceptionDId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>33</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>A</td>\n",
       "      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>\\( 3 \\times 2+(4-5) \\)</td>\n",
       "      <td>\\( 3 \\times(2+4-5) \\)</td>\n",
       "      <td>Does not need brackets</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1612</td>\n",
       "      <td>Simplify an algebraic fraction by factorising ...</td>\n",
       "      <td>1077</td>\n",
       "      <td>Simplifying Algebraic Fractions</td>\n",
       "      <td>D</td>\n",
       "      <td>Simplify the following, if possible: \\( \\frac{...</td>\n",
       "      <td>\\( m+1 \\)</td>\n",
       "      <td>\\( m+2 \\)</td>\n",
       "      <td>\\( m-1 \\)</td>\n",
       "      <td>Does not simplify</td>\n",
       "      <td>2142</td>\n",
       "      <td>143</td>\n",
       "      <td>2142</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2774</td>\n",
       "      <td>Calculate the range from a list of data</td>\n",
       "      <td>339</td>\n",
       "      <td>Range and Interquartile Range from a List of Data</td>\n",
       "      <td>B</td>\n",
       "      <td>Tom and Katie are discussing the \\( 5 \\) plant...</td>\n",
       "      <td>Only\\nTom</td>\n",
       "      <td>Only\\nKatie</td>\n",
       "      <td>Both Tom and Katie</td>\n",
       "      <td>Neither is correct</td>\n",
       "      <td>1287</td>\n",
       "      <td>-1</td>\n",
       "      <td>1287</td>\n",
       "      <td>1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2377</td>\n",
       "      <td>Recall and use the intersecting diagonals prop...</td>\n",
       "      <td>88</td>\n",
       "      <td>Properties of Quadrilaterals</td>\n",
       "      <td>C</td>\n",
       "      <td>The angles highlighted on this rectangle with ...</td>\n",
       "      <td>acute</td>\n",
       "      <td>obtuse</td>\n",
       "      <td>\\( 90^{\\circ} \\)</td>\n",
       "      <td>Not enough information</td>\n",
       "      <td>1180</td>\n",
       "      <td>1180</td>\n",
       "      <td>-1</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3387</td>\n",
       "      <td>Substitute positive integer values into formul...</td>\n",
       "      <td>67</td>\n",
       "      <td>Substitution into Formula</td>\n",
       "      <td>A</td>\n",
       "      <td>The equation \\( f=3 r^{2}+3 \\) is used to find...</td>\n",
       "      <td>\\( 30 \\)</td>\n",
       "      <td>\\( 27 \\)</td>\n",
       "      <td>\\( 51 \\)</td>\n",
       "      <td>\\( 24 \\)</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionId  ConstructId                                      ConstructName  \\\n",
       "0           0          856  Use the order of operations to carry out calcu...   \n",
       "1           1         1612  Simplify an algebraic fraction by factorising ...   \n",
       "2           2         2774            Calculate the range from a list of data   \n",
       "3           3         2377  Recall and use the intersecting diagonals prop...   \n",
       "4           4         3387  Substitute positive integer values into formul...   \n",
       "\n",
       "   SubjectId                                        SubjectName CorrectAnswer  \\\n",
       "0         33                                             BIDMAS             A   \n",
       "1       1077                    Simplifying Algebraic Fractions             D   \n",
       "2        339  Range and Interquartile Range from a List of Data             B   \n",
       "3         88                       Properties of Quadrilaterals             C   \n",
       "4         67                          Substitution into Formula             A   \n",
       "\n",
       "                                        QuestionText            AnswerAText  \\\n",
       "0  \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...  \\( 3 \\times(2+4)-5 \\)   \n",
       "1  Simplify the following, if possible: \\( \\frac{...              \\( m+1 \\)   \n",
       "2  Tom and Katie are discussing the \\( 5 \\) plant...              Only\\nTom   \n",
       "3  The angles highlighted on this rectangle with ...                  acute   \n",
       "4  The equation \\( f=3 r^{2}+3 \\) is used to find...               \\( 30 \\)   \n",
       "\n",
       "              AnswerBText            AnswerCText             AnswerDText  \\\n",
       "0  \\( 3 \\times 2+(4-5) \\)  \\( 3 \\times(2+4-5) \\)  Does not need brackets   \n",
       "1               \\( m+2 \\)              \\( m-1 \\)       Does not simplify   \n",
       "2             Only\\nKatie     Both Tom and Katie      Neither is correct   \n",
       "3                  obtuse       \\( 90^{\\circ} \\)  Not enough information   \n",
       "4                \\( 27 \\)               \\( 51 \\)                \\( 24 \\)   \n",
       "\n",
       "   MisconceptionAId  MisconceptionBId  MisconceptionCId  MisconceptionDId  \n",
       "0                -1                -1                -1              1672  \n",
       "1              2142               143              2142                -1  \n",
       "2              1287                -1              1287              1073  \n",
       "3              1180              1180                -1              1180  \n",
       "4                -1                -1                -1              1818  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Use the order of operations to carry out calcu...\n",
       "1    Simplify an algebraic fraction by factorising ...\n",
       "2              Calculate the range from a list of data\n",
       "3    Recall and use the intersecting diagonals prop...\n",
       "4    Substitute positive integer values into formul...\n",
       "Name: ConstructName, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"ConstructName\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "Question: {question}\n",
    "Incorrect Answer: {incorrect_answer}\n",
    "Correct Answer: {correct_answer}\n",
    "Construct Name: {construct_name}\n",
    "Subject Name: {subject_name}\n",
    "\n",
    "Your task: Identify the misconception behind Incorrect Answer. Answer concisely and generically inside <response>$$INSERT TEXT HERE$$</response>. Before answering the question think step by step concisely in 1-2 sentence inside the <thinking>$$INSERT TEXT HERE$$</thinking> tag. Respond with your final misconception inside the <response>$$INSERT TEXT HERE$$</response> tag.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer: PreTrainedTokenizerFast = AutoTokenizer.from_pretrained(\n",
    "    \"meta-llama/Llama-3.2-1B\", chat_template=PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_template(\n",
    "    construct_name: str,\n",
    "    subject_name: str,\n",
    "    question: str,\n",
    "    incorrect_answer: str,\n",
    "    correct_answer: str,\n",
    "    tokenizer: PreTrainedTokenizerFast,\n",
    ") -> str:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": PROMPT.format(\n",
    "                construct_name=construct_name,\n",
    "                subject_name=subject_name,\n",
    "                question=question,\n",
    "                incorrect_answer=incorrect_answer,\n",
    "                correct_answer=correct_answer,\n",
    "            ),\n",
    "        }\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "for i, row in df_train.iterrows():\n",
    "    for target_option in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        answer_col = f\"Answer{target_option}Text\"\n",
    "        misconception_col = f\"Misconception{target_option}Id\"\n",
    "        # ignore question-answer pairs that are correct and have no misconception\n",
    "        if row[\"CorrectAnswer\"] == target_option or row[misconception_col] == -1:\n",
    "            continue\n",
    "        question_answer_id = f\"{row['QuestionId']}_{target_option}\"\n",
    "        train_dataset.append(\n",
    "            (\n",
    "                question_answer_id,\n",
    "                apply_template(\n",
    "                    construct_name=row[\"ConstructName\"],\n",
    "                    subject_name=row[\"SubjectName\"],\n",
    "                    question=row[\"QuestionText\"],\n",
    "                    incorrect_answer=row[misconception_col],\n",
    "                    correct_answer=row[answer_col],\n",
    "                    tokenizer=tokenizer,\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "df = pd.DataFrame(train_dataset, columns=[\"QuestionId_Answer\", \"Prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: {question}\n",
      "Incorrect Answer: {incorrect_answer}\n",
      "Correct Answer: {correct_answer}\n",
      "Construct Name: {construct_name}\n",
      "Subject Name: {subject_name}\n",
      "\n",
      "Your task: Identify the misconception behind Incorrect Answer. Answer concisely and generically inside <response>$$INSERT TEXT HERE$$</response>. Before answering the question think step by step concisely in 1-2 sentence inside the <thinking>$$INSERT TEXT HERE$$</thinking> tag. Respond with your final misconception inside the <response>$$INSERT TEXT HERE$$</response> tag.\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0][\"Prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "miscon_df = pd.read_csv(\"data/misconception_mapping.csv\", index_col=\"MisconceptionId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MisconceptionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Does not know that angles in a triangle sum to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        MisconceptionName\n",
       "count                                                2587\n",
       "unique                                               2587\n",
       "top     Does not know that angles in a triangle sum to...\n",
       "freq                                                    1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miscon_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MisconceptionName</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MisconceptionId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does not know that angles in a triangle sum to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uses dividing fractions method for multiplying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Believes there are 100 degrees in a full turn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thinks a quadratic without a non variable term...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Believes addition of terms and powers of terms...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 MisconceptionName\n",
       "MisconceptionId                                                   \n",
       "0                Does not know that angles in a triangle sum to...\n",
       "1                Uses dividing fractions method for multiplying...\n",
       "2                    Believes there are 100 degrees in a full turn\n",
       "3                Thinks a quadratic without a non variable term...\n",
       "4                Believes addition of terms and powers of terms..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miscon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = miscon_df.to_dict()[\"MisconceptionName\"]\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\",\n",
    "    num_labels=len(miscon_df),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"miscon_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_imdb[\"train\"],\n",
    "    eval_dataset=tokenized_imdb[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = []\n",
    "for i, row in df_test.iterrows():\n",
    "    for target_option in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        answer_col = f\"Answer{target_option}Text\"\n",
    "        question_answer_id = f\"{row['QuestionId']}_{target_option}\"\n",
    "        test_dataset.append(\n",
    "            (\n",
    "                question_answer_id,\n",
    "                apply_template(\n",
    "                    construct_name=row[\"ConstructName\"],\n",
    "                    subject_name=row[\"SubjectName\"],\n",
    "                    question=row[\"QuestionText\"],\n",
    "                    incorrect_answer=\"{misconception_col}\",\n",
    "                    correct_answer=row[answer_col],\n",
    "                    tokenizer=tokenizer,\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "df = pd.DataFrame(test_dataset, columns=[\"QuestionId_Answer\", \"Prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId_Answer</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1869_A</td>\n",
       "      <td>\\nQuestion: {question}\\nIncorrect Answer: {inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1869_B</td>\n",
       "      <td>\\nQuestion: {question}\\nIncorrect Answer: {inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1869_C</td>\n",
       "      <td>\\nQuestion: {question}\\nIncorrect Answer: {inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1869_D</td>\n",
       "      <td>\\nQuestion: {question}\\nIncorrect Answer: {inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1870_A</td>\n",
       "      <td>\\nQuestion: {question}\\nIncorrect Answer: {inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1870_B</td>\n",
       "      <td>\\nQuestion: {question}\\nIncorrect Answer: {inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1870_C</td>\n",
       "      <td>\\nQuestion: {question}\\nIncorrect Answer: {inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1870_D</td>\n",
       "      <td>\\nQuestion: {question}\\nIncorrect Answer: {inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1871_A</td>\n",
       "      <td>\\nQuestion: {question}\\nIncorrect Answer: {inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1871_B</td>\n",
       "      <td>\\nQuestion: {question}\\nIncorrect Answer: {inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1871_C</td>\n",
       "      <td>\\nQuestion: {question}\\nIncorrect Answer: {inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1871_D</td>\n",
       "      <td>\\nQuestion: {question}\\nIncorrect Answer: {inc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionId_Answer                                             Prompt\n",
       "0             1869_A  \\nQuestion: {question}\\nIncorrect Answer: {inc...\n",
       "1             1869_B  \\nQuestion: {question}\\nIncorrect Answer: {inc...\n",
       "2             1869_C  \\nQuestion: {question}\\nIncorrect Answer: {inc...\n",
       "3             1869_D  \\nQuestion: {question}\\nIncorrect Answer: {inc...\n",
       "4             1870_A  \\nQuestion: {question}\\nIncorrect Answer: {inc...\n",
       "5             1870_B  \\nQuestion: {question}\\nIncorrect Answer: {inc...\n",
       "6             1870_C  \\nQuestion: {question}\\nIncorrect Answer: {inc...\n",
       "7             1870_D  \\nQuestion: {question}\\nIncorrect Answer: {inc...\n",
       "8             1871_A  \\nQuestion: {question}\\nIncorrect Answer: {inc...\n",
       "9             1871_B  \\nQuestion: {question}\\nIncorrect Answer: {inc...\n",
       "10            1871_C  \\nQuestion: {question}\\nIncorrect Answer: {inc...\n",
       "11            1871_D  \\nQuestion: {question}\\nIncorrect Answer: {inc..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c0cd164a0d49c7903a1184e01caed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "clf = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"meta-llama/Llama-3.2-1B\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.8921873569488525}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=model_id, torch_dtype=torch.bfloat16, device_map=\"auto\"\n",
    ")\n",
    "\n",
    "pipe(\"The key to life is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "    \"data/train.csv\",\n",
    "    dtype={\n",
    "        \"MisconceptionAId\": \"Int64\",\n",
    "        \"MisconceptionBId\": \"Int64\",\n",
    "        \"MisconceptionCId\": \"Int64\",\n",
    "        \"MisconceptionDId\": \"Int64\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping_df = pd.read_csv(\"data/misconception_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
